# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mk8jiT0A6nqTSwHBmf4T8l0SKhgvdkKM

** Loading , inspecting dataset & Importing libraries**
"""

!pip install kaggle
!mkdir ~/.kaggle
!touch ~/.kaggle/kaggle.json

api_token = {"username":"","key":""}

import json

with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d priyamchoksi/100000-diabetes-clinical-dataset
!unzip 100000-diabetes-clinical-dataset.zip

#Importing libraries
import warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)
from matplotlib import pyplot
import numpy as np
import pandas as pd
import pandas as read_csv
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder,StandardScaler

df = pd.read_csv('diabetes_dataset.csv')

def get_information(df):
    print("Datashape: ", df.shape)

    print("Dataset information*************************")
    df.info()

    for col in df.columns:
        print(f"{col}: {df[col].nunique()}")
    print("Unique numbers********************")

    for col in df.columns:
        print(f"{col}: {df[col].isnull().sum()}")
    print("Totall number of null number********************")

    print("Dublicated rows count: ", df.duplicated().sum())

    print("Stastical describtion of Dataset*****************************",)
    return df.describe().transpose()

# Calling function
get_information(df)

# Deleting duplicated rows
df = df.drop_duplicates()
print("Dublicated rows count: ", df.duplicated().sum())

"""**Data preparation and EDA***

***bold text***
"""

df_race = df[["race:AfricanAmerican", "race:Asian", "race:Caucasian", "race:Hispanic", "race:Other"]]
by_race = pd.from_dummies(df_race)
dff = df.drop(columns = ["race:AfricanAmerican", "race:Asian", "race:Caucasian", "race:Hispanic", "race:Other"])
dff.insert(2, "race", by_race)
dff["race"] = dff["race"].str.replace("race:", "")
dff["race"] = dff["race"].str.replace("AfricanAmerican", "African-American")

bins = [0, 18, 25, 35, 45, 55, 65, np.inf]
age_order = ["0-18", "18-24", "25-34", "35-44", "45-54", "55-64", "65+"]
dff.insert(3, "age_cat", pd.cut(dff["age"], bins, labels = age_order))

bins = [0, 18.5, 25, 30, 35, 40, np.inf]
bmi_order = ["Underweight", "Normal", "Overweight", "Moderately Obese", "Severely Obese", "Morbidly Obese"]
dff.insert(9, "bmi_cat", pd.cut(dff["bmi"], bins, labels = bmi_order))

dff["smoking_history"] = dff["smoking_history"].str.title()
dff = dff[dff["smoking_history"] != "No Info"]

columns = ['gender', 'race', 'age_cat', 'location', 'hypertension', 'heart_disease', 'smoking_history', 'bmi_cat',
           'diabetes']

for col in columns:

    if col in ['gender', 'race', 'age_cat', 'location', 'smoking_history', 'bmi_cat']:
        dff[col] = dff[col].astype("category")

    else:
        dff[col] = dff[col].astype("bool")

print(dff.head())

columns = list(dff.columns)
new_name = [col.title() for col in columns]

for c, n in zip(columns, new_name):
    dff = dff.rename(columns = {c:n})

dff = dff.rename(columns = {"Age_Cat":"Age Group",
                            "Heart_Disease":"Heart Disease",
                            "Smoking_History":"Smoking History",
                            "Bmi_Cat":"BMI Category",
                            "Bmi":"BMI",
                            "Hba1C_Level":"HbA1C Level",
                            "Blood_Glucose_Level":"Blood Glucose Level"
                           }
                )
print(dff.head())


diabetes_yes = dff[dff["Diabetes"] == True]
diabetes_no = dff[dff["Diabetes"] == False].sample(n = diabetes_yes.shape[0], ignore_index = True, random_state = 42)

sample = pd.concat([diabetes_yes, diabetes_no], axis = 0).reset_index(drop = True)

sample.head()

df_encoded = sample.drop(columns = ["Age Group", "BMI Category"])
le = LabelEncoder()

df_encoded["Gender"] = le.fit_transform(df_encoded["Gender"])
df_encoded["Location"] = le.fit_transform(df_encoded["Location"])
df_encoded["Race"] = le.fit_transform(df_encoded["Race"])
df_encoded["Smoking History"] = le.fit_transform(df_encoded["Smoking History"])
df_encoded


y = df_encoded["Diabetes"].values

X_train, X_test, y_train, y_test = train_test_split(df_encoded, y, test_size = 0.2, random_state = 42)
#scaler_X = StandardScaler()

#X_train_scaled = scaler_X.fit_transform(X_train)
#X_test_scaled = scaler_X.fit_transform(X_test)

"""***MODEL DEFINE AND EVALUATION***"""

!pip install pycaret
from pycaret.classification import *

# Initialize PyCaret setup
clf = setup(data=X_train, target=y_train, session_id=42,remove_outliers = True,normalize = True,fix_imbalance = True, verbose=False )
# Compare models and select the best one
best_model = compare_models()
# Get the best model
print(best_model)
# Finalize the model
final_model = finalize_model(best_model)

# Finalize the model
final_model = finalize_model(best_model)
# Predict on the test data
y_pred = predict_model(final_model, data=X_test)
print(y_pred)

#tuned = tune_model(final_model)
plot_model(final_model, plot = 'auc')

plot_model(final_model, plot = 'pr')

plot_model(final_model, plot = 'confusion_matrix')